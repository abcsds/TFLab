{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T03.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M35WAjJ6Ibqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle as pk\n",
        "# from google.colab import drive\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "# drive.mount('/content/gdrive', force_remount=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XofuOztIbqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "917d5b21-89f8-4365-c429-92b12a03a63b"
      },
      "source": [
        "!git clone https://github.com/RafaelDrumond/PeekDB.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PeekDB'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Total 86 (delta 0), reused 0 (delta 0), pack-reused 86\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF2YZ3VJIbqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a21a049f-31e8-4b87-ca9a-686939aa0239"
      },
      "source": [
        "!mkdir -p val\n",
        "!cp ./PeekDB/Motion/Actor2* ./val/\n",
        "!ls ./val/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actor2Crouching.txt  Actor2Running.txt\tActor2Walking.txt\n",
            "Actor2Idle.txt\t     Actor2Swing.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrBqGCSoIbq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "e5319b0b-35bf-4d8e-e6b3-b06d7acf5d95"
      },
      "source": [
        "!mkdir -p tr\n",
        "!cp ./PeekDB/Motion/Actor* ./tr/\n",
        "!rm ./tr/Actor2*\n",
        "!rm ./tr/Actor0*\n",
        "!ls ./tr/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actor10Crouching.txt  Actor4Crouching.txt  Actor7Crouching.txt\n",
            "Actor10Idle.txt       Actor4Idle.txt\t   Actor7Idle.txt\n",
            "Actor10Running.txt    Actor4Running.txt    Actor7Running.txt\n",
            "Actor10Swing.txt      Actor4Swing.txt\t   Actor7Swing.txt\n",
            "Actor10Walking.txt    Actor4Walking.txt    Actor7Walking.txt\n",
            "Actor1Crouching.txt   Actor5Crouching.txt  Actor8Crouching.txt\n",
            "Actor1Idle.txt\t      Actor5Idle.txt\t   Actor8Idle.txt\n",
            "Actor1Running.txt     Actor5Running.txt    Actor8Running.txt\n",
            "Actor1Swing.txt       Actor5Swing.txt\t   Actor8Swing.txt\n",
            "Actor1Walking.txt     Actor5Walking.txt    Actor8Walking.txt\n",
            "Actor3Crouching.txt   Actor6Crouching.txt  Actor9Crouching.txt\n",
            "Actor3Idle.txt\t      Actor6Idle.txt\t   Actor9Idle.txt\n",
            "Actor3Running.txt     Actor6Running.txt    Actor9Running.txt\n",
            "Actor3Swing.txt       Actor6Swing.txt\t   Actor9Swing.txt\n",
            "Actor3Walking.txt     Actor6Walking.txt    Actor9Walking.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf-CjodhIbq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def motionLoad(classes, directory, window = 60):\n",
        "\n",
        "  if directory.endswith(\"/\"):\n",
        "    dire = directory\n",
        "  else:\n",
        "    dire = directory+\"/\"\n",
        "  file_list = os.listdir(dire)\n",
        "#   print(file_list)\n",
        "  file_list = [i for i in file_list if any(s in i for s in classes)]\n",
        "#   print(file_list)\n",
        "  instances = []\n",
        "  labels = []\n",
        "  #READ FILES\n",
        "  for f in file_list:\n",
        "    label = [0.,0.,0.]\n",
        "    index = 0\n",
        "    #CHECK CLASS\n",
        "    for c, cla in enumerate(classes):\n",
        "      if cla in f:\n",
        "        label[c] = 1.0\n",
        "    #OPEN FILE\n",
        "    with open(directory+f) as doc:\n",
        "      lines = doc.readlines()\n",
        "    end = 0\n",
        "    #READ AND APPEND\n",
        "    while index < len(lines):\n",
        "      count = 0\n",
        "      subin = []\n",
        "      if index+window < len(lines):\n",
        "        while count < window:\n",
        "          count +=1\n",
        "          out = lines[index].split(\"|m \")[1].split(\" |class\")[0].split(\" \") # if you make changes look here\n",
        "          out = [float(i) for i in out]\n",
        "          subin.append(out)\n",
        "          index +=1 # pay attention here!\n",
        "        instances.append(np.array(subin))\n",
        "        labels.append   (np.array(label))\n",
        "      else:\n",
        "        index = len(lines)\n",
        "  return instances, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O_zZ9xgIbq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = [\"Crouching\", \"Idle\", \"Running\", \"Siwing\", \"Walking\"]\n",
        "actions = [\"Crouching\", \"Running\", \"Swing\"]\n",
        "window  = 40\n",
        "n_actions = len(actions)\n",
        "\n",
        "xv, yv = motionLoad(actions, \"./val/\", window)\n",
        "xt, yt = motionLoad([\"Crouching\", \"Running\", \"Swing\"], \"./tr/\", window)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6q8eAKzIbrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e5cc346-52b0-4eee-867c-2510256eee21"
      },
      "source": [
        "n_tr = len(xt)\n",
        "n_ts = len(xv)\n",
        "print(n_tr, n_ts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4816 532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbtz8CUSIbrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e65d411a-2b58-4541-eab9-059ca7c02acc"
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None, window, 20], name=\"Inputs\")\n",
        "y = tf.placeholder(tf.float32, [None, n_actions], name=\"Labels\")\n",
        "\n",
        "model = tf.keras.layers.LSTM(200, name=\"LSTM1\")(x)\n",
        "model = tf.layers.Dropout(.5, name=\"dropout1\")(model)\n",
        "model = tf.layers.Dense(27, name=\"dense1\")(model)\n",
        "model = tf.layers.Dense(n_actions, name=\"dense2\")(model)\n",
        "\n",
        "# loss\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=model), name=\"loss\")\n",
        "\n",
        "# optimizer\n",
        "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
        "\n",
        "# Accuracy\n",
        "prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32), name=\"accuracy\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi5mY0IVIbrQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1094
        },
        "outputId": "789f4e18-4a1d-48bf-9d7e-6e129e108e0d"
      },
      "source": [
        "epochs = 20\n",
        "batch_size = 50\n",
        "batches = n_tr // batch_size\n",
        "print(\"Begin Session\")\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    counter = 0\n",
        "    tic = time()\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Start Epoch {:>2}\".format(epoch+1))\n",
        "        t = time()\n",
        "        for i in range(batches):\n",
        "            tloss, tacc, _ = sess.run([loss, accuracy, optimizer],\n",
        "                                         feed_dict={\n",
        "                                             x: xt[i*batch_size:(i+1)*batch_size], \n",
        "                                             y: yt[i*batch_size:(i+1)*batch_size]})\n",
        "        print(\"Training   Loss: {:>8.4f}, Training   Accuracy: {:>8.6f}\".format(tloss, tacc))\n",
        "        print(\"Epoch time: \", time() - t)\n",
        "    vloss, vacc = sess.run([loss, accuracy], feed_dict={x: xv, y: yv})\n",
        "    print(\"Validation Loss: {:>8.4f}, Validation Accuracy: {:>8.6f}\".format(vloss, vacc))\n",
        "    print(\"Training time:\", time() - tic)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin Session\n",
            "Start Epoch  1\n",
            "Training   Loss:   0.3956, Training   Accuracy: 0.920000\n",
            "Epoch time:  24.22856092453003\n",
            "Start Epoch  2\n",
            "Training   Loss:   0.3146, Training   Accuracy: 0.860000\n",
            "Epoch time:  23.47832441329956\n",
            "Start Epoch  3\n",
            "Training   Loss:   0.1872, Training   Accuracy: 0.900000\n",
            "Epoch time:  23.26110029220581\n",
            "Start Epoch  4\n",
            "Training   Loss:   0.0645, Training   Accuracy: 1.000000\n",
            "Epoch time:  23.149770975112915\n",
            "Start Epoch  5\n",
            "Training   Loss:   0.0391, Training   Accuracy: 1.000000\n",
            "Epoch time:  23.177053213119507\n",
            "Start Epoch  6\n",
            "Training   Loss:   0.0883, Training   Accuracy: 0.940000\n",
            "Epoch time:  23.173630952835083\n",
            "Start Epoch  7\n",
            "Training   Loss:   0.0388, Training   Accuracy: 1.000000\n",
            "Epoch time:  23.092628240585327\n",
            "Start Epoch  8\n",
            "Training   Loss:   0.0197, Training   Accuracy: 1.000000\n",
            "Epoch time:  23.734130859375\n",
            "Start Epoch  9\n",
            "Training   Loss:   0.0131, Training   Accuracy: 1.000000\n",
            "Epoch time:  23.014073610305786\n",
            "Start Epoch 10\n",
            "Training   Loss:   0.0275, Training   Accuracy: 1.000000\n",
            "Epoch time:  22.980873107910156\n",
            "Start Epoch 11\n",
            "Training   Loss:   0.0314, Training   Accuracy: 0.980000\n",
            "Epoch time:  23.0115327835083\n",
            "Start Epoch 12\n",
            "Training   Loss:   0.0061, Training   Accuracy: 1.000000\n",
            "Epoch time:  22.973183631896973\n",
            "Start Epoch 13\n",
            "Training   Loss:   0.0103, Training   Accuracy: 1.000000\n",
            "Epoch time:  23.039036750793457\n",
            "Start Epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-82e5fec81bb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                                          feed_dict={\n\u001b[1;32m     15\u001b[0m                                              \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                              y: yt[i*batch_size:(i+1)*batch_size]})\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training   Loss: {:>8.4f}, Training   Accuracy: {:>8.6f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtacc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8z0pzb6Ibre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1163
        },
        "outputId": "228ec6c4-188f-4bd2-c190-5855d29e914b"
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None, window, 20], name=\"Inputs\")\n",
        "y = tf.placeholder(tf.float32, [None, n_actions], name=\"Labels\")\n",
        "\n",
        "model = tf.layers.Conv1D(filters=128, kernel_size=8, name=\"Conv1\")(x)\n",
        "model = tf.layers.BatchNormalization()(model)\n",
        "model = tf.nn.relu(model)\n",
        "\n",
        "model = tf.layers.Conv1D(filters=256, kernel_size=5, name=\"Conv2\")(x)\n",
        "model = tf.layers.BatchNormalization()(model)\n",
        "model = tf.nn.relu(model)\n",
        "\n",
        "model = tf.layers.Conv1D(filters=128, kernel_size=3, name=\"Conv3\")(x)\n",
        "model = tf.layers.BatchNormalization()(model)\n",
        "model = tf.nn.relu(model)\n",
        "\n",
        "model = tf.keras.layers.GlobalAveragePooling1D()(model)\n",
        "model = tf.layers.Dense(n_actions, name=\"dense2\")(model)\n",
        "\n",
        "\n",
        "# loss\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=model), name=\"loss\")\n",
        "\n",
        "# optimizer\n",
        "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
        "\n",
        "# Accuracy\n",
        "prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32), name=\"accuracy\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 20\n",
        "batches = n_tr // batch_size\n",
        "print(\"Begin Session\")\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    counter = 0\n",
        "    tic = time()\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Start Epoch {:>2}\".format(epoch+1))\n",
        "        t = time()\n",
        "        for i in range(batches):\n",
        "            tloss, tacc, _ = sess.run([loss, accuracy, optimizer],\n",
        "                                         feed_dict={\n",
        "                                             x: xt[i*batch_size:(i+1)*batch_size], \n",
        "                                             y: yt[i*batch_size:(i+1)*batch_size]})\n",
        "        print(\"Training   Loss: {:>8.4f}, Training   Accuracy: {:>8.6f}\".format(tloss, tacc))\n",
        "        print(\"Epoch time: \", time() - t)\n",
        "    vloss, vacc = sess.run([loss, accuracy], feed_dict={x: xv, y: yv})\n",
        "    print(\"Validation Loss: {:>8.4f}, Validation Accuracy: {:>8.6f}\".format(vloss, vacc))\n",
        "    print(\"Training time:\", time() - tic)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Begin Session\n",
            "Start Epoch  1\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  1.195894479751587\n",
            "Start Epoch  2\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9991838932037354\n",
            "Start Epoch  3\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9755303859710693\n",
            "Start Epoch  4\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9592993259429932\n",
            "Start Epoch  5\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9776597023010254\n",
            "Start Epoch  6\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.975836992263794\n",
            "Start Epoch  7\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9915745258331299\n",
            "Start Epoch  8\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9747292995452881\n",
            "Start Epoch  9\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9810945987701416\n",
            "Start Epoch 10\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9723916053771973\n",
            "Start Epoch 11\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.966498613357544\n",
            "Start Epoch 12\n",
            "Training   Loss:   0.3757, Training   Accuracy: 0.900000\n",
            "Epoch time:  0.9721400737762451\n",
            "Start Epoch 13\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9627847671508789\n",
            "Start Epoch 14\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9836258888244629\n",
            "Start Epoch 15\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9724202156066895\n",
            "Start Epoch 16\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9409723281860352\n",
            "Start Epoch 17\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.965461254119873\n",
            "Start Epoch 18\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9604165554046631\n",
            "Start Epoch 19\n",
            "Training   Loss:   0.0002, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.9359545707702637\n",
            "Start Epoch 20\n",
            "Training   Loss:   0.0000, Training   Accuracy: 1.000000\n",
            "Epoch time:  0.917067289352417\n",
            "Validation Loss:   0.0558, Validation Accuracy: 0.986842\n",
            "Training time: 19.668389320373535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcxwSVbaLxwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}