{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "(xt,yt), (xv,yv) = load_data()\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "enc.fit(yt)\n",
    "\n",
    "yt = enc.transform(yt).toarray()\n",
    "yv = enc.transform(yv).toarray()\n",
    "\n",
    "train_items = xt.shape[0]\n",
    "test_items  = xv.shape[0]\n",
    "\n",
    "logsPath = \"./Graph01\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3], name=\"Features\")\n",
    "y = tf.placeholder(tf.float32, [None, 10], name=\"Labels\")\n",
    "\n",
    "model = tf.layers.Conv2D(32,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"1_Conv\")(x)\n",
    "model = tf.layers.BatchNormalization(name=\"1_batchNormalization\")(model)\n",
    "model = tf.layers.Conv2D(32,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"2_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"2_batchNormalization\")(model)\n",
    "model = tf.layers.MaxPooling2D(pool_size=(2, 2), strides=1, name=\"1_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.2, name=\"1_Dropout\")(model)\n",
    "model = tf.layers.Conv2D(64,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"3_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"3_batchNormalization\")(model)\n",
    "model = tf.layers.Conv2D(64,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"4_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"4_batchNormalization\")(model)\n",
    "model = tf.layers.MaxPooling2D(pool_size=(2, 2), strides=1, name=\"2_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.2, name=\"2_Dropout\")(model)\n",
    "model = tf.layers.Conv2D(128,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"5_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"5_batchNormalization\")(model)\n",
    "model = tf.layers.Conv2D(128,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"6_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"6_batchNormalization\")(model)\n",
    "model = tf.layers.MaxPooling2D(pool_size=(2, 2), strides=1, name=\"2_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.2, name=\"2_Dropout\")(model)\n",
    "model = tf.layers.Flatten(name=\"1_Flatten\")(model)\n",
    "model = tf.layers.Dense(2048, name=\"1_dense\")(model)\n",
    "model = tf.layers.Dense(10, name=\"2_dense\")(model)\n",
    "\n",
    "# loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=model), name=\"loss\")\n",
    "tf.summary.scalar(\"Loss\", cost)\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32), name=\"accuracy\")\n",
    "tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "epochs = 50\n",
    "batchSize = 10\n",
    "n_batches = train_items // batchSize\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin Session\")\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter(logsPath, sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Start Epoch {:>2}\".format(epoch+1))\n",
    "        t = time()\n",
    "        # for i in range(n_batches):\n",
    "        #     sess.run(optimizer, feed_dict={x: xt[i*batchSize:(i+1)*batchSize],\n",
    "        #                                    y: yt[i*batchSize:(i+1)*batchSize]})\n",
    "        counter += 1\n",
    "        merge = tf.summary.merge_all()\n",
    "        summary = sess.run(merge, feed_dict={x: xv, y: yv})\n",
    "        train_writer.add_summary(summary, counter)\n",
    "        print(\"Epoch {:>2}:  \".format(epoch + 1), end='\\n')\n",
    "        it = np.random.randint(0, train_items, batchSize)\n",
    "        \n",
    "        vloss, vacc = sess.run([cost, accuracy], feed_dict={x: xv, y: yv})\n",
    "        # tloss, tacc = sess.run([cost, accuracy], feed_dict={x: xt[it], y: yt[it]})\n",
    "        print(\"Validation Loss: {:>8.4f}, Validation Accuracy: {:>8.6f}\".format(vloss, vacc))\n",
    "        # print(\"Training   Loss: {:>8.4f}, Training   Accuracy: {:>8.6f}\".format(tloss, tacc))\n",
    "        print(\"Epoch time: \", time() - t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
