{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "WUmecs2bXdww",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load pacakages\n",
        "For our exercises, you should always use the standar packages from Google Colab unless stated otherwise."
      ]
    },
    {
      "metadata": {
        "id": "Mr3-yF_1XGO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e2f36816-12d1-49b2-be80-20aa33fd6f55"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(pd.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "1.14.6\n",
            "0.22.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1bD2az2VXwtx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data function\n",
        "Here you must write down your data loading function"
      ]
    },
    {
      "metadata": {
        "id": "a8w13xdzXtNe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loadTrainData (default_dir=\"/default/path/if/needed\"):\n",
        "  x = np.random.rand(16000,1) # write our data loading procedures\n",
        "  y = np.sin(x)\n",
        "  return x , y\n",
        "\n",
        "def loadTestData (default_dir=\"/default/path/if/needed\"):\n",
        "  x = np.random.rand(160,1) # write our data loading procedures\n",
        "  y = np.sin(x)\n",
        "  return x , y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CYjifVRqbLMr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Structure your model\n",
        "Create a class to define and use your model"
      ]
    },
    {
      "metadata": {
        "id": "y0Fv2md1YyKx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "  def __init__(self,learning_rate=0.0001, mini_batches=16, neurons=[4]):\n",
        "    self.lr = learning_rate\n",
        "    self.mb = mini_batches\n",
        "    \n",
        "    self.input = tf.placeholder(tf.float32, shape=(None, 1), name=\"X\")\n",
        "    self.label = tf.placeholder(tf.float32, shape=(None, 1), name=\"Y\")\n",
        "    \n",
        "    self.output = self.input\n",
        "    for neuron in neurons:\n",
        "      self.output = tf.layers.dense(self.output, neuron)\n",
        "      \n",
        "    self.output = tf.layers.dense(self.output, 1)\n",
        "    \n",
        "    self.loss = (self.output - self.label) * (self.output - self.label)\n",
        "    self.loss = tf.reduce_mean(self.loss)\n",
        "    \n",
        "  def get_loss(self):\n",
        "    return self.loss\n",
        "  \n",
        "  def get_xy(self):\n",
        "    return self.input, self.label\n",
        "  \n",
        "  def get_output(self):\n",
        "    return self.output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dG8wbG2IbT2_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create an optimization routine\n",
        "Define your optimization steps"
      ]
    },
    {
      "metadata": {
        "id": "KaVxN-qMaY9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Optimizer:\n",
        "  def __init__(self,model):\n",
        "    self.model     = model\n",
        "    self.loss      = model.get_loss()\n",
        "    self.X, self.Y = model.get_xy()\n",
        "    self.mb        = model.mb\n",
        "    self.output    = model.get_output()\n",
        "    \n",
        "    self.opt       = tf.train.GradientDescentOptimizer(learning_rate = model.lr)\n",
        "    self.optAction = self.opt.minimize(self.loss)\n",
        "    \n",
        "  def batching (self, size):\n",
        "#     print (size)\n",
        "    r=np.arange(int(size))\n",
        "    np.random.shuffle(r)\n",
        "#     print(r)\n",
        "    return r\n",
        "  \n",
        "  def train (self, dataX, dataY, verbose):\n",
        "    i     = 0\n",
        "    loss  = 0\n",
        "    count = 0\n",
        "    batchOrder = self.batching(len(dataX))\n",
        "#     print (batchOrder)\n",
        "    while (i+self.mb <= len(dataX)):\n",
        "        \n",
        "      mbX, mbY   = dataX[batchOrder[i:i+self.mb]] , dataY[batchOrder[i:i+self.mb]]\n",
        "        \n",
        "      _ , mbLoss = self.sess.run([self.optAction, self.loss],\n",
        "                                   feed_dict={\n",
        "                                       self.X:mbX,\n",
        "                                       self.Y:mbY\n",
        "                                   })\n",
        "      if verbose>1:\n",
        "        print(\"\\t Inner loss: \"+str(mbLoss))\n",
        "          \n",
        "      loss  += mbLoss\n",
        "      i     += self.mb\n",
        "      count += 1\n",
        "    loss = loss / count\n",
        "    return loss\n",
        "  \n",
        "  def test  (self, dataX, dataY, verbose):\n",
        "    i     = 0\n",
        "    loss  = 0\n",
        "    count = 0\n",
        "    batchOrder = self.batching(len(dataX)) \n",
        "    while (i+self.mb <= len(dataX)):\n",
        "        \n",
        "      mbX, mbY   = dataX[i:i+self.mb] , dataY[i:i+self.mb]\n",
        "        \n",
        "      mbLoss = self.sess.run(self.loss,\n",
        "                                   feed_dict={\n",
        "                                       self.X:mbX,\n",
        "                                       self.Y:mbY\n",
        "                                   })          \n",
        "      loss  += mbLoss\n",
        "      i     += self.mb\n",
        "      count += 1\n",
        "    loss = loss / count\n",
        "    return loss\n",
        "  \n",
        "  def run   (self, dataX, dataY, testX, testY, epochs, verbose=2):\n",
        "    historyTR = []\n",
        "    historyTS = []\n",
        "    with tf.Session() as self.sess:\n",
        "      self.sess.run(tf.global_variables_initializer())\n",
        "      lossTS = self.test  (testX , testY, verbose)\n",
        "      historyTR.append(lossTS)\n",
        "      historyTS.append(lossTS)\n",
        "      for i in range(epochs):\n",
        "        \n",
        "        lossTR = self.train (dataX , dataY, verbose)\n",
        "        lossTS = self.test  (testX , testY, verbose)\n",
        "        if verbose > 0:\n",
        "          print(\"Epoch \" +str(i+1)+\" : Train Loss = \" + str(lossTR)+\" :  Test Loss = \" + str(lossTS))\n",
        "        historyTR.append(lossTR)\n",
        "        historyTS.append(lossTS)\n",
        "    return historyTR, historyTS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLQQTXhZb2N4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Structure your calls\n",
        "Here you should make the main calls"
      ]
    },
    {
      "metadata": {
        "id": "gH38m2ykb18C",
        "colab_type": "code",
        "outputId": "1b118c91-5a14-4a27-ff28-f98818221e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1864
        }
      },
      "cell_type": "code",
      "source": [
        "x  , y  = loadTrainData ()\n",
        "xt , yt = loadTestData  ()\n",
        "\n",
        "model  = Model ()\n",
        "opt    = Optimizer (model)\n",
        "tr, ts = opt.run (x, y, xt, yt, 100, verbose=1)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Train Loss = 0.02467498129233718 :  Test Loss = 0.010996215930208563\n",
            "Epoch 2 : Train Loss = 0.007199721531476825 :  Test Loss = 0.004542905814014375\n",
            "Epoch 3 : Train Loss = 0.0037176029487745836 :  Test Loss = 0.003206985001452267\n",
            "Epoch 4 : Train Loss = 0.0028649217528873123 :  Test Loss = 0.0027817410998977722\n",
            "Epoch 5 : Train Loss = 0.0025152299426845276 :  Test Loss = 0.0025209138169884683\n",
            "Epoch 6 : Train Loss = 0.002276085881108884 :  Test Loss = 0.0023009659955278037\n",
            "Epoch 7 : Train Loss = 0.0020747595785651357 :  Test Loss = 0.0021023256005719302\n",
            "Epoch 8 : Train Loss = 0.0018960576488170774 :  Test Loss = 0.0019226024742238224\n",
            "Epoch 9 : Train Loss = 0.0017357862322533038 :  Test Loss = 0.00176035639597103\n",
            "Epoch 10 : Train Loss = 0.0015917070283030625 :  Test Loss = 0.0016138205071911215\n",
            "Epoch 11 : Train Loss = 0.0014621105112018996 :  Test Loss = 0.0014817478600889443\n",
            "Epoch 12 : Train Loss = 0.0013456452958635055 :  Test Loss = 0.0013636514078825713\n",
            "Epoch 13 : Train Loss = 0.0012408867511549033 :  Test Loss = 0.0012571731407660992\n",
            "Epoch 14 : Train Loss = 0.0011467510267102626 :  Test Loss = 0.0011618273274507374\n",
            "Epoch 15 : Train Loss = 0.0010621241111366544 :  Test Loss = 0.0010765214101411402\n",
            "Epoch 16 : Train Loss = 0.000986066076264251 :  Test Loss = 0.0010000923299230634\n",
            "Epoch 17 : Train Loss = 0.0009177513633330818 :  Test Loss = 0.0009310422698035836\n",
            "Epoch 18 : Train Loss = 0.0008563349336327519 :  Test Loss = 0.0008692925388459116\n",
            "Epoch 19 : Train Loss = 0.0008011438085522969 :  Test Loss = 0.0008140024903696031\n",
            "Epoch 20 : Train Loss = 0.0007516146028938238 :  Test Loss = 0.0007642004813533277\n",
            "Epoch 21 : Train Loss = 0.0007071177977049956 :  Test Loss = 0.000719647342339158\n",
            "Epoch 22 : Train Loss = 0.0006671651608194225 :  Test Loss = 0.0006796776840928942\n",
            "Epoch 23 : Train Loss = 0.0006312689982005395 :  Test Loss = 0.0006437262258259579\n",
            "Epoch 24 : Train Loss = 0.0005990235316858161 :  Test Loss = 0.0006116632925113663\n",
            "Epoch 25 : Train Loss = 0.000570071957896289 :  Test Loss = 0.0005828326451592147\n",
            "Epoch 26 : Train Loss = 0.0005440561057039303 :  Test Loss = 0.0005567620013607666\n",
            "Epoch 27 : Train Loss = 0.0005207374338715453 :  Test Loss = 0.0005337636714102701\n",
            "Epoch 28 : Train Loss = 0.0004997959239117335 :  Test Loss = 0.0005131968617206439\n",
            "Epoch 29 : Train Loss = 0.00048098824176122433 :  Test Loss = 0.0004946191183989868\n",
            "Epoch 30 : Train Loss = 0.0004641270344145596 :  Test Loss = 0.0004783091164426878\n",
            "Epoch 31 : Train Loss = 0.00044896193691238296 :  Test Loss = 0.00046339938708115367\n",
            "Epoch 32 : Train Loss = 0.00043536538537591695 :  Test Loss = 0.000450504757463932\n",
            "Epoch 33 : Train Loss = 0.00042317168816225604 :  Test Loss = 0.0004387598892208189\n",
            "Epoch 34 : Train Loss = 0.00041222340904641894 :  Test Loss = 0.00042822556861210614\n",
            "Epoch 35 : Train Loss = 0.00040239536369335836 :  Test Loss = 0.00041877468465827404\n",
            "Epoch 36 : Train Loss = 0.0003935762660257751 :  Test Loss = 0.0004104271065443754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f9f3258f7f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopt\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mOptimizer\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-4e16c2858ab3>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataX, dataY, testX, testY, epochs, verbose)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mlossTR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdataY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mlossTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-4e16c2858ab3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataX, dataY, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m                                    feed_dict={\n\u001b[1;32m     31\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmbX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmbY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                                    })\n\u001b[1;32m     34\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8lROgCU6BEoh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PLOT"
      ]
    },
    {
      "metadata": {
        "id": "qEax4t3y_hSx",
        "colab_type": "code",
        "outputId": "eb3ed153-18bf-47dc-c595-a10f2de726cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "print(matplotlib.__version__)\n",
        "plt.plot(ts, label='TEST')\n",
        "plt.plot(tr, label='TRAIN')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niDQQhb6ISANR6IuINJD/D7Iw6ah2nhLhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oqRlbPI6xvsj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# EXERCISE 0\n",
        "## Your goal is to:\n",
        "### Expand this model to receive multiple inputs and the output must be of size 2.\n",
        "Your network must receive 5 different numbers, and output the sumation of cossines of the numbers and the summation of the sines.\n",
        "\n",
        "### Add L2 and L1 regularizations directly on the loss function and include their coeficcients as hyper-parameters\n",
        "\n",
        "### Add comments to this code\n",
        "\n",
        "## Feel free to make changes, as long as they make the code clear and keep a similar structure"
      ]
    }
  ]
}