{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jknoIGJEQbRi"
   },
   "source": [
    "# Google Drive Loading\n",
    "It requires to mount the directory first\n",
    "Please put the data in the same directory as below to avoid probems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TvzBuDPTX5SR",
    "outputId": "c28e85e4-dabd-4528-d3d0-b0138d5edce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 1180s 7us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "###\n",
    "  # Prints and image\n",
    "###\n",
    "import matplotlib.pyplot as plt\n",
    "def showIMG(data):\n",
    "  plt.imshow(data)\n",
    "\n",
    "(xt,yt), (xv,yv) = load_data()\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "enc.fit(yt)\n",
    "\n",
    "yt = enc.transform(yt).toarray()\n",
    "yv = enc.transform(yv).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "cNvWRgUyMrz_",
    "outputId": "5c9736e2-0774-4c16-d782-afad4293bdaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(xt.shape, yt.shape)\n",
    "train_items = xt.shape[0]\n",
    "test_items  = xv.shape[0]\n",
    "showIMG(xt[30])\n",
    "len(yt)\n",
    "# showIMG(xv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNyHJn0ARd3A"
   },
   "source": [
    "# Task 1\n",
    "\n",
    "## Build a CNN architecture to classify this data-set\n",
    "\n",
    "Hint: https://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf\n",
    "\n",
    "Run for 50 epochs and report your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hb2LfoEhEk2y"
   },
   "source": [
    "# Response\n",
    "Installing colab to visualize training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NiCKBgJfEoru",
    "outputId": "bb732e80-63e0-4661-ee55-1269bdb8ebd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardcolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "bJIZLEcGFJfB",
    "outputId": "63297c09-8f95-4004-f957-f51d3c3e3105"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for 8 seconds...\n",
      "TensorBoard link:\n",
      "http://935aa5e3.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "from tensorboardcolab import TensorBoardColab\n",
    "tbc=TensorBoardColab()\n",
    "logsPath = \"./Graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsPath = \"./Graph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rITn1mph3xG7"
   },
   "source": [
    "# First try\n",
    "In this first atempt no data augmentation will be used, and a simple CNN will be used.\n",
    "The model takes the 32x32 images as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "pUh1L3E64Owd",
    "outputId": "facfd76e-dded-48b6-a16f-29cbfb729436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3], name=\"Features\")\n",
    "y = tf.placeholder(tf.float32, [None, 10], name=\"Labels\")\n",
    "\n",
    "model = tf.layers.Conv2D(64,[6,6],padding=\"same\",activation=tf.nn.relu, name=\"1_Conv\")(x)\n",
    "model = tf.layers.MaxPooling2D((2,2), (2,2), name=\"1_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.8, name=\"1_Dropout\")(model)\n",
    "model = tf.layers.Conv2D(64,[3,3],padding=\"same\",activation=tf.nn.relu, name=\"2_Conv\")(model)\n",
    "model = tf.layers.MaxPooling2D((2,2), (2,2), name=\"2_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.8, name=\"2_Dropout\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"batchNormalization\")(model)\n",
    "model = tf.layers.Flatten(name=\"Flatten\")(model)\n",
    "model = tf.layers.Dense(280, name=\"1_dense\")(model)\n",
    "model = tf.layers.Dense(10, name=\"2_dense\")(model)\n",
    "\n",
    "# loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=model))\n",
    "tf.summary.histogram(\"Loss\", cost)\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32), name='accuracy')\n",
    "tf.summary.histogram(\"Accuracy\", accuracy)\n",
    "\n",
    "epochs = 50\n",
    "batchSize = 1000\n",
    "n_batches = train_items // batchSize\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "hnOXdXnCG9T7",
    "outputId": "0688324c-dcf4-48e6-a466-7c0304c72a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Session\n",
      "Variables Initialized\n",
      "Start Epoch  1\n",
      "..............."
     ]
    }
   ],
   "source": [
    "histT = []\n",
    "histV = []\n",
    "print(\"Begin Session\")\n",
    "with tf.Session() as sess:\n",
    "#   if tf.gfile.Exists(logsPath+\"model.ckpt\"):\n",
    "#     saver.restore(sess, logsPath+\"model.ckpt\")\n",
    "#     print(\"Model restored!\")\n",
    "#   train_writer = tf.summary.FileWriter(logsPath, sess.graph)\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  print(\"Variables Initialized\")\n",
    "    \n",
    "  counter = 0\n",
    "  for epoch in range(epochs):\n",
    "    print(\"Start Epoch {:>2}\".format(epoch + 1))\n",
    "    for i in range(1, n_batches + 1):\n",
    "      print(\".\", end=\"\")\n",
    "      counter += 1\n",
    "      merge = tf.summary.merge_all()\n",
    "      summary, _ = sess.run([merge, optimizer],\n",
    "                            feed_dict={x: xt[i*batchSize:(i+1)*batchSize],\n",
    "                                       y: yt[i*batchSize:(i+1)*batchSize]})\n",
    "    train_writer.add_summary(summary, counter)\n",
    "    print(\"Epoch {:>2}:  \".format(epoch + 1), end=\"\\n\")\n",
    "    vloss, vacc = sess.run([cost,accuracy],\n",
    "                            feed_dict={x: xv,\n",
    "                                       y: yv})\n",
    "    tloss, tacc = sess.run([cost,accuracy],\n",
    "                             feed_dict={x: xt,\n",
    "                                        y: yt})\n",
    "    print(\"Validation Loss: {:>8.4f}, Validation Accuracy: {:>8.6f}\".format(vloss, vacc))\n",
    "    print(\"Training   Loss: {:>8.4f}, Training   Accuracy: {:>8.6f}\".format(tloss, tacc))\n",
    "    histT.append(tacc)\n",
    "    histV.append(vacc)\n",
    "\n",
    "    # Save Model\n",
    "  train_writer.flush()\n",
    "#   save_path = saver.save(sess, './image_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9neldp1w_gNC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "print(matplotlib.__version__)\n",
    "plt.plot(histT, label='TEST')\n",
    "plt.plot(histV, label='TRAIN')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eW1qEAhuV1Xp"
   },
   "source": [
    "# A better architecture. \n",
    "The following architecture has been observed to reach an accuracy of 90%:\n",
    "\n",
    "- https://arxiv.org/abs/1502.03167\n",
    "- http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kehsfbeIWBh8"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3], name=\"Features\")\n",
    "y = tf.placeholder(tf.float32, [None, 10], name=\"Labels\")\n",
    "\n",
    "model = tf.layers.Conv2D(32,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"1_Conv\")(x)\n",
    "model = tf.layers.BatchNormalization(name=\"1_batchNormalization\")(model)\n",
    "model = tf.layers.Conv2D(32,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"2_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"2_batchNormalization\")(model)\n",
    "model = tf.layers.MaxPooling2D(pool_size=(2, 2), strides=1, name=\"1_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.2, name=\"1_Dropout\")(model)\n",
    "model = tf.layers.Conv2D(64,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"3_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"3_batchNormalization\")(model)\n",
    "model = tf.layers.Conv2D(64,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"4_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"4_batchNormalization\")(model)\n",
    "model = tf.layers.MaxPooling2D(pool_size=(2, 2), strides=1, name=\"2_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.2, name=\"2_Dropout\")(model)\n",
    "model = tf.layers.Conv2D(128,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"5_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"5_batchNormalization\")(model)\n",
    "model = tf.layers.Conv2D(128,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"6_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"6_batchNormalization\")(model)\n",
    "model = tf.layers.MaxPooling2D(pool_size=(2, 2), strides=1, name=\"2_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.2, name=\"2_Dropout\")(model)\n",
    "model = tf.layers.Flatten(name=\"1_Flatten\")(model)\n",
    "model = tf.layers.Dense(2048, name=\"1_dense\")(model)\n",
    "model = tf.layers.Dense(10, name=\"2_dense\")(model)\n",
    "\n",
    "# loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=model))\n",
    "tf.summary.histogram(\"Loss\", cost)\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32), name='accuracy')\n",
    "tf.summary.histogram(\"Accuracy\", accuracy)\n",
    "\n",
    "epochs = 50\n",
    "batchSize = 1000\n",
    "n_batches = train_items // batchSize\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbGPAqh2WB0m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Session\n",
      "Variables Initialized\n",
      "Start Epoch  1\n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Epoch  1:  \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,128,30,30] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node 6_Conv/Conv2D (defined at <ipython-input-6-c11098bd802c>:19) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node Mean (defined at <ipython-input-6-c11098bd802c>:28) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op '6_Conv/Conv2D', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-c11098bd802c>\", line 19, in <module>\n    model = tf.layers.Conv2D(128,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"6_Conv\")(model)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,128,30,30] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node 6_Conv/Conv2D (defined at <ipython-input-6-c11098bd802c>:19) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node Mean (defined at <ipython-input-6-c11098bd802c>:28) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,128,30,30] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node 6_Conv/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5baa369bac1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     vloss, vacc = sess.run([cost,accuracy],\n\u001b[1;32m     25\u001b[0m                             feed_dict={x: xv,\n\u001b[0;32m---> 26\u001b[0;31m                                        y: yv})\n\u001b[0m\u001b[1;32m     27\u001b[0m     tloss, tacc = sess.run([cost,accuracy],\n\u001b[1;32m     28\u001b[0m                              feed_dict={x: xt,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,128,30,30] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node 6_Conv/Conv2D (defined at <ipython-input-6-c11098bd802c>:19) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node Mean (defined at <ipython-input-6-c11098bd802c>:28) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op '6_Conv/Conv2D', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-c11098bd802c>\", line 19, in <module>\n    model = tf.layers.Conv2D(128,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"6_Conv\")(model)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,128,30,30] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node 6_Conv/Conv2D (defined at <ipython-input-6-c11098bd802c>:19) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node Mean (defined at <ipython-input-6-c11098bd802c>:28) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "histT = []\n",
    "histV = []\n",
    "print(\"Begin Session\")\n",
    "with tf.Session() as sess:\n",
    "#   if tf.gfile.Exists(logsPath+\"model.ckpt\"):\n",
    "#     saver.restore(sess, logsPath+\"model.ckpt\")\n",
    "#     print(\"Model restored!\")\n",
    "  train_writer = tf.summary.FileWriter(logsPath, sess.graph)\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  print(\"Variables Initialized\")\n",
    "    \n",
    "  counter = 0\n",
    "  for epoch in range(epochs):\n",
    "    print(\"Start Epoch {:>2}\".format(epoch + 1))\n",
    "    for i in range(n_batches):\n",
    "      print(\".\", end=\"\")\n",
    "      counter += 1\n",
    "      merge = tf.summary.merge_all()\n",
    "      summary, _ = sess.run([merge, optimizer],\n",
    "                            feed_dict={x: xt[i*batchSize:(i+1)*batchSize],\n",
    "                                       y: yt[i*batchSize:(i+1)*batchSize]})\n",
    "    train_writer.add_summary(summary, counter)\n",
    "    print(\"Epoch {:>2}:  \".format(epoch + 1), end='\\n')\n",
    "    vloss, vacc = sess.run([cost,accuracy],\n",
    "                            feed_dict={x: xv,\n",
    "                                       y: yv})\n",
    "    tloss, tacc = sess.run([cost,accuracy],\n",
    "                             feed_dict={x: xt,\n",
    "                                        y: yt})\n",
    "    print(\"Validation Loss: {:>8.4f}, Validation Accuracy: {:>8.6f}\".format(vloss, vacc))\n",
    "    print(\"Training   Loss: {:>8.4f}, Training   Accuracy: {:>8.6f}\".format(tloss, tacc))\n",
    "    histT.append(tacc)\n",
    "    histV.append(vacc)\n",
    "\n",
    "    # Save Model\n",
    "  train_writer.flush()\n",
    "#   save_path = saver.save(sess, './image_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4m-owwAhYhc0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "print(matplotlib.__version__)\n",
    "plt.plot(histT, label='TEST')\n",
    "plt.plot(histV, label='TRAIN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLWfsOJLcnoe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Session\n",
      "Variables Initialized\n",
      "Start Epoch  1\n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Epoch  1:  \n",
      "Validation Loss:   1.8143, Validation Accuracy: 0.325500\n",
      "Training   Loss:   1.7954, Training   Accuracy: 0.332000\n",
      "Start Epoch  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Epoch  2:  \n",
      "Validation Loss:   1.6619, Validation Accuracy: 0.381700\n",
      "Training   Loss:   1.6445, Training   Accuracy: 0.385240\n",
      "Start Epoch  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Epoch  3:  \n",
      "Validation Loss:   1.5784, Validation Accuracy: 0.416100\n",
      "Training   Loss:   1.5685, Training   Accuracy: 0.423240\n",
      "Start Epoch  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3], name=\"Features\")\n",
    "y = tf.placeholder(tf.float32, [None, 10], name=\"Labels\")\n",
    "\n",
    "model = tf.layers.Conv2D(16,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"1_Conv\")(x)\n",
    "model = tf.layers.BatchNormalization(name=\"1_batchNormalization\")(model)\n",
    "model = tf.layers.Conv2D(16,[3,3],padding=\"same\",activation=tf.nn.elu, name=\"2_Conv\")(model)\n",
    "model = tf.layers.BatchNormalization(name=\"2_batchNormalization\")(model)\n",
    "model = tf.layers.MaxPooling2D(pool_size=(32, 32), strides=1, name=\"1_Pool\")(model)\n",
    "model = tf.layers.Dropout(0.2, name=\"2_Dropout\")(model)\n",
    "model = tf.layers.Flatten(name=\"1_Flatten\")(model)\n",
    "model = tf.layers.Dense(2048, name=\"1_dense\")(model)\n",
    "model = tf.layers.Dense(10, name=\"2_dense\")(model)\n",
    "\n",
    "# loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=model))\n",
    "tf.summary.histogram(\"Loss\", cost)\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "prediction = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32), name='accuracy')\n",
    "tf.summary.histogram(\"Accuracy\", accuracy)\n",
    "\n",
    "epochs = 50\n",
    "batchSize = 10\n",
    "n_batches = train_items // batchSize\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "histT = []\n",
    "histV = []\n",
    "print(\"Begin Session\")\n",
    "with tf.Session() as sess:\n",
    "#   if tf.gfile.Exists(logsPath+\"model.ckpt\"):\n",
    "#     saver.restore(sess, logsPath+\"model.ckpt\")\n",
    "#     print(\"Model restored!\")\n",
    "  train_writer = tf.summary.FileWriter(logsPath, sess.graph)\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  print(\"Variables Initialized\")\n",
    "    \n",
    "  counter = 0\n",
    "  for epoch in range(epochs):\n",
    "    print(\"Start Epoch {:>2}\".format(epoch + 1))\n",
    "    for i in range(n_batches):\n",
    "      print(\".\", end=\"\")\n",
    "      counter += 1\n",
    "      merge = tf.summary.merge_all()\n",
    "      summary, _ = sess.run([merge, optimizer],\n",
    "                            feed_dict={x: xt[i*batchSize:(i+1)*batchSize],\n",
    "                                       y: yt[i*batchSize:(i+1)*batchSize]})\n",
    "    train_writer.add_summary(summary, counter)\n",
    "    print(\"\\nEpoch {:>2}:  \".format(epoch + 1), end='\\n')\n",
    "    vloss, vacc = sess.run([cost,accuracy],\n",
    "                            feed_dict={x: xv,\n",
    "                                       y: yv})\n",
    "    tloss, tacc = sess.run([cost,accuracy],\n",
    "                             feed_dict={x: xt,\n",
    "                                        y: yt})\n",
    "    print(\"Validation Loss: {:>8.4f}, Validation Accuracy: {:>8.6f}\".format(vloss, vacc))\n",
    "    print(\"Training   Loss: {:>8.4f}, Training   Accuracy: {:>8.6f}\".format(tloss, tacc))\n",
    "    histT.append(tacc)\n",
    "    histV.append(vacc)\n",
    "\n",
    "    # Save Model\n",
    "  train_writer.flush()\n",
    "#   save_path = saver.save(sess, './image_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Loading_CIFAR_10.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
